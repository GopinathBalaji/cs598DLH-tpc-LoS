2024-04-25 00:40:08,905 - INFO - Config:
2024-04-25 00:40:08,905 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/MIMIC/LoS/TPCMSE",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "MIMIC",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPCMSE",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "mse",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 15,
    "n_layers": 9,
    "name": "TPCMSE",
    "no_diag": true,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 820320524,
    "share_weights": false,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2024-04-25 00:40:09,243 - INFO - Experiment set up.
2024-04-25 00:40:09,376 - INFO - TempPointConv(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=1, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(202, 1212, kernel_size=(4,), stride=(1,), groups=101)
      (bn_temp): MyBatchNorm1d(1212, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=237, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1482, 1368, kernel_size=(4,), stride=(1,), dilation=(3,), groups=114)
      (bn_temp): MyBatchNorm1d(1368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1462, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1651, 1524, kernel_size=(4,), stride=(1,), dilation=(6,), groups=127)
      (bn_temp): MyBatchNorm1d(1524, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1618, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1820, 1680, kernel_size=(4,), stride=(1,), dilation=(9,), groups=140)
      (bn_temp): MyBatchNorm1d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1774, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1989, 1836, kernel_size=(4,), stride=(1,), dilation=(12,), groups=153)
      (bn_temp): MyBatchNorm1d(1836, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1930, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(2158, 1992, kernel_size=(4,), stride=(1,), dilation=(15,), groups=166)
      (bn_temp): MyBatchNorm1d(1992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2086, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2327, 2148, kernel_size=(4,), stride=(1,), dilation=(18,), groups=179)
      (bn_temp): MyBatchNorm1d(2148, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2242, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2496, 2304, kernel_size=(4,), stride=(1,), dilation=(21,), groups=192)
      (bn_temp): MyBatchNorm1d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2398, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2665, 2460, kernel_size=(4,), stride=(1,), dilation=(24,), groups=205)
      (bn_temp): MyBatchNorm1d(2460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2554, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2867, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2867, out_features=17, bias=True)
)
2024-04-25 00:56:09,009 - INFO - Custom bins confusion matrix:
2024-04-25 00:56:09,022 - INFO - [[   792 187924 371837 192525  96179  49386  26929  15739  24231   3016]
 [   426  83273 204818 136099  81265  47554  28465  17395  28695   3593]
 [   215  41125 114505  89339  59752  38590  24946  16044  28147   3750]
 [   185  22809  70883  61945  45331  31135  20922  14179  26569   3825]
 [   124  14390  48291  45648  34795  25311  17736  12265  24040   3601]
 [    87  10301  34225  34298  27920  20947  15063  10878  21532   3424]
 [    82   7362  25420  27039  23190  17951  13112   9420  19528   3293]
 [    80   5561  19639  21821  19224  15239  11438   8216  17540   3074]
 [   294  15046  58529  72386  67568  56040  43442  32482  73338  14530]
 [   204  10004  40409  57006  58174  51240  42290  32764  81661  19905]]
2024-04-25 00:56:14,145 - INFO - Epoch: 0 | Train Loss: 7908.4717
2024-04-25 00:59:56,569 - INFO - Custom bins confusion matrix:
2024-04-25 00:59:56,570 - INFO - [[    1 34199 80359 42233 24514 13843  7388  4227  2574     2]
 [    0 12191 41807 29169 22065 15303  8984  4984  3137     0]
 [    0  4477 21852 17996 15049 13703  9266  5704  3305     0]
 [    0  1999 11977 11990 10882 10299  8458  6268  3114     0]
 [    0  1088  7192  7943  8061  7901  7389  5726  3052     0]
 [    0   670  4270  5063  6123  6432  6216  4935  3080     0]
 [    0   509  2740  3782  4803  4500  5152  4798  2848     0]
 [    0   301  1871  3095  3695  3602  4440  4291  2863     0]
 [    0   389  4323  8297 12013 13449 15717 17570 14872     0]
 [    0   173  2313  4319  6652  9625 13622 16660 18677     0]]
2024-04-25 00:59:58,362 - INFO - Epoch: 0 | Validation Loss: 3179.0358
2024-04-25 01:15:41,874 - INFO - Custom bins confusion matrix:
2024-04-25 01:15:41,875 - INFO - [[  9246 165689 384695 170366  97728  55674  32359  19399  30344   3058]
 [  2997  67784 194496 121339  86002  56831  36428  23186  38559   3961]
 [  1072  29629 100753  77055  63330  46585  32577  21872  39121   4419]
 [   477  15034  57099  51033  46634  37675  28004  19608  37632   4587]
 [   291   8573  36274  36042  35175  30241  23553  17064  34396   4592]
 [   153   5399  23901  26060  27437  24543  20115  15001  31624   4442]
 [   128   3648  16192  19989  22188  20458  17064  13307  29046   4377]
 [    62   2468  11594  15529  17979  17458  14903  11312  26316   4211]
 [   156   5283  29229  44683  58370  61533  55653  45813 112445  20490]
 [    15   1974  14243  28774  44302  51136  50791  44664 127759  29999]]
2024-04-25 01:15:46,612 - INFO - Epoch: 1 | Train Loss: 7479.4141
2024-04-25 01:19:21,576 - INFO - Custom bins confusion matrix:
2024-04-25 01:19:21,577 - INFO - [[   28 59540 61935 32691 21059 13560  9380  5596  5526    25]
 [    6 23047 34375 23019 18230 13970 10276  6778  7908    31]
 [    0  9353 18090 14435 12083 11559  9573  6935  9287    37]
 [    0  4277 10131  9526  8626  8403  7890  6707  9369    58]
 [    0  2359  5979  6340  6064  6590  6315  5713  8951    41]
 [    0  1316  3492  4140  4434  5135  5102  4818  8342    10]
 [    0   848  2329  2797  3618  3848  3820  3924  7948     0]
 [    0   573  1553  2213  2708  3207  3149  3386  7364     5]
 [    0   947  3219  5879  8199 10786 11917 12166 33453    64]
 [    0   523  1769  2651  4369  5938  8683 10292 37636   180]]
2024-04-25 01:19:23,438 - INFO - Epoch: 1 | Validation Loss: 3001.9443
2024-04-25 01:35:10,805 - INFO - Custom bins confusion matrix:
2024-04-25 01:35:10,806 - INFO - [[ 54792 221516 268864 184271  92360  57761  34901  20713  30650   2730]
 [ 18413  96432 145685 123499  80214  58593  39401  25110  40491   3745]
 [  7137  44245  76078  76215  58670  47900  34912  24269  42502   4485]
 [  2967  22152  43821  49322  42225  38251  30283  21986  41977   4799]
 [  1518  12685  27547  33869  31367  30166  25522  19301  39355   4871]
 [   784   7851  17908  23972  24163  24224  21484  16714  36582   4993]
 [   567   5094  12155  17658  19126  20083  18023  14972  33765   4954]
 [   345   3461   8434  13100  15471  16894  15576  12905  30826   4820]
 [   545   7166  20868  36741  48095  57792  57298  50009 130829  24312]
 [   156   2843   9629  20840  32810  45188  48773  46317 148423  38678]]
2024-04-25 01:35:15,352 - INFO - Epoch: 2 | Train Loss: 7260.8362
2024-04-25 01:38:50,290 - INFO - Custom bins confusion matrix:
2024-04-25 01:38:50,291 - INFO - [[ 3632 65542 58994 25405 17838 13716  9942  6264  7934    73]
 [  752 25868 35012 17823 14935 13336 11036  7803 11007    68]
 [  182 10611 18375 11191 10180 10435  9489  7477 13349    63]
 [   67  4521 10619  7424  7119  7404  7248  6737 13761    87]
 [   27  2248  6360  4897  4825  5412  5980  5284 13202   117]
 [    2  1248  3599  2960  3604  3994  4660  4493 12072   157]
 [    1   719  2366  1996  2403  3456  3576  3369 11143   103]
 [    9   428  1583  1438  1912  2592  2964  2749 10396    87]
 [   10   603  3035  3696  4810  8160 10418 10327 45097   474]
 [    0   295  1808  1938  2211  3604  5404  7985 47626  1170]]
2024-04-25 01:38:52,194 - INFO - Epoch: 2 | Validation Loss: 2890.2243
2024-04-25 01:54:43,537 - INFO - Custom bins confusion matrix:
2024-04-25 01:54:43,538 - INFO - [[112149 222984 223156 151662 124628  51751  31706  19097  28500   2925]
 [ 41940 106042 126321 104392  98494  52721  35605  23650  38615   3803]
 [ 16399  50803  69054  65028  69212  44170  32667  23007  41457   4616]
 [  7198  26447  39627  42592  49705  35746  28448  21037  41738   5245]
 [  3509  15211  25034  28773  36492  28515  23903  18642  40458   5664]
 [  1841   8838  16328  20007  27846  22648  20413  16582  38172   6000]
 [  1128   5678  10814  14390  21699  18770  17353  14540  36068   5957]
 [   592   3648   7408  10523  17297  15556  14971  13041  32824   5972]
 [   789   6952  17305  27828  51654  52284  53742  48557 142554  31990]
 [   321   2945   7834  14189  31609  36763  42511  43197 159812  54476]]
2024-04-25 01:54:48,160 - INFO - Epoch: 3 | Train Loss: 7014.8836
2024-04-25 01:58:20,831 - INFO - Custom bins confusion matrix:
2024-04-25 01:58:20,832 - INFO - [[ 6308 46543 59042 35790 27421 15732  8840  4558  4906   200]
 [ 1708 18064 31565 23976 21999 15810 10136  6390  7692   300]
 [  386  7011 15403 14842 15281 12487  9218  6629  9803   292]
 [  148  2767  8523  9322  9930  9925  7717  6013 10281   361]
 [   63  1200  4898  5983  6922  7449  6606  4932  9947   352]
 [   12   619  2699  3655  4611  5847  5556  4184  9214   392]
 [    5   338  1443  2482  3420  4637  4349  3673  8368   417]
 [    3   153   986  1688  2598  3452  3512  3427  8047   292]
 [    4   165  1786  3306  6744 10379 12242 12593 37450  1961]
 [    0   104   775  1670  3082  5582  7609  9054 38556  5609]]
2024-04-25 01:58:22,643 - INFO - Epoch: 3 | Validation Loss: 2838.2082
2024-04-25 02:14:11,296 - INFO - Custom bins confusion matrix:
2024-04-25 02:14:11,297 - INFO - [[169215 209617 184204 137146 101568  91375  32040  17143  23794   2456]
 [ 66591 106457 108240  94127  79795  81802  36436  21800  32896   3439]
 [ 27589  53666  60574  58409  55862  65715  32992  21411  36217   3978]
 [ 12422  28413  35450  38241  40176  52680  29191  19843  36914   4453]
 [  6128  16572  22496  25712  28803  42276  24943  18207  36094   4970]
 [  3138   9683  14481  18036  21709  34262  21473  15997  34629   5267]
 [  1785   5798   9673  12810  16625  28339  18499  14245  32989   5634]
 [  1009   3725   6688   9137  12661  23737  16065  12705  30443   5662]
 [  1538   7569  15587  23508  36048  79276  56936  48348 133631  31214]
 [   652   3034   6515  11067  19565  60039  45828  42277 148477  56203]]
2024-04-25 02:14:15,998 - INFO - Epoch: 4 | Train Loss: 6868.3472
2024-04-25 02:17:51,835 - INFO - Custom bins confusion matrix:
2024-04-25 02:17:51,836 - INFO - [[20055 51300 46997 30540 19017 25136 11076  3262  1827   130]
 [ 6037 22726 26712 21534 15991 23878 13344  4440  2873   105]
 [ 1725  9035 13954 14033 11135 19107 13177  5178  3893   115]
 [  497  3792  7764  8828  7282 15369 12023  4940  4328   164]
 [  168  1724  4404  5448  5017 11950 10348  4736  4439   118]
 [   66   905  2245  3224  3441  9428  8997  4098  4274   111]
 [   22   487  1376  2037  2437  7534  7450  3640  4005   144]
 [   23   287   828  1419  1925  5773  6553  3414  3804   132]
 [   25   418  1559  3144  4549 17819 25198 14227 18887   804]
 [    0   158   728  1692  2386  8552 17155 15060 24511  1799]]
2024-04-25 02:17:53,656 - INFO - Epoch: 4 | Validation Loss: 3136.0548
2024-04-25 02:33:41,294 - INFO - Custom bins confusion matrix:
2024-04-25 02:33:41,295 - INFO - [[215188 199022 160918 123905  79566  62345  79245  20956  25188   2225]
 [ 89054 105971  97356  84780  63903  54805  73165  25240  34324   2985]
 [ 38122  55400  55855  53221  44808  42075  60649  24871  37787   3625]
 [ 17420  29670  33674  34506  32089  32996  51151  23154  38974   4149]
 [  8718  17493  21795  23156  23028  25044  42798  21468  38353   4348]
 [  4661  10391  13721  15939  16872  19629  36427  19158  37246   4631]
 [  2541   6410   9484  11135  12538  15815  31136  16965  35489   4884]
 [  1396   4224   6307   8095   9654  12702  26644  14827  32983   5000]
 [  2570   8721  15086  20644  26155  37280  91642  57919 144594  29044]
 [  1295   3762   6809  10252  14506  23271  72196  48827 157299  55440]]
2024-04-25 02:33:46,147 - INFO - Epoch: 5 | Train Loss: 6389.0708
2024-04-25 02:37:21,835 - INFO - Custom bins confusion matrix:
2024-04-25 02:37:21,836 - INFO - [[ 7612 36482 50851 39778 24929 16287 32662   524   176    39]
 [ 2016 14474 25622 25234 19353 14272 35829   527   287    26]
 [  475  5440 12061 14853 12920 10807 34033   531   227     5]
 [  134  1926  6235  8817  8967  7668 30398   537   264    41]
 [   28   752  3174  5458  5923  5936 26190   551   306    34]
 [    3   390  1601  2927  3954  4547 22569   565   201    32]
 [    0   163   932  1719  2798  3638 19040   618   178    46]
 [    0   110   574  1312  1935  2691 16798   441   258    39]
 [    0   223  1085  2661  4790  7488 66630  2205  1394   154]
 [    0   203   505  1329  3026  4315 56903  3445  2220    95]]
2024-04-25 02:37:23,473 - INFO - Epoch: 5 | Validation Loss: 3588.2028
2024-04-25 02:52:36,635 - INFO - Custom bins confusion matrix:
2024-04-25 02:52:36,987 - INFO - [[233225 192057 149315 116345  81835  50072  51860  67325  24711   1813]
 [ 97829 103901  91321  79005  63610  46483  51140  60995  34832   2467]
 [ 42187  54436  53002  49553  43638  35428  43482  52389  39227   3071]
 [ 19342  30044  31919  31897  30600  27461  36472  45419  41190   3439]
 [  9737  17656  20170  21674  21774  20806  30604  39556  40279   3945]
 [  5119  10605  13326  14643  15861  16018  25638  34327  38939   4199]
 [  2931   6551   8981  10509  11676  12731  21862  29729  37054   4373]
 [  1780   4181   6217   7683   8913  10188  18147  25677  34693   4353]
 [  3450   9860  15255  19636  24502  29267  61592  93184 151550  25359]
 [  1227   3858   6760   9923  13402  17973  45729  77781 167608  49396]]
2024-04-25 02:52:41,698 - INFO - Epoch: 6 | Train Loss: 6087.5615
2024-04-25 02:56:20,165 - INFO - Custom bins confusion matrix:
2024-04-25 02:56:20,166 - INFO - [[13294 45537 49754 35603 22859 13723 10355 13803  4348    64]
 [ 3425 18892 26349 24577 18373 12975 10782 15948  6259    60]
 [  965  6868 12997 14730 12847 10048  9263 16240  7344    50]
 [  257  2455  6990  9093  8383  7607  7589 15009  7574    30]
 [   45  1068  3541  5323  5651  5668  5974 13599  7468    15]
 [    0   525  1822  2905  3606  4094  4874 12006  6926    31]
 [    1   293  1003  1745  2403  3094  3733 10222  6587    51]
 [    8   165   550  1215  1893  2345  2949  8681  6284    68]
 [    0   277  1204  2613  4524  5734  8447 34592 28866   373]
 [    0    54   479  1078  2247  2846  4282 24140 35618  1297]]
2024-04-25 02:56:22,147 - INFO - Epoch: 6 | Validation Loss: 3248.3368
2024-04-25 03:12:13,133 - INFO - Custom bins confusion matrix:
2024-04-25 03:12:13,134 - INFO - [[257559 191460 144760 109129  79472  48897  28762  76230  30326   1963]
 [112019 107817  90173  76270  61376  44467  30335  65276  41287   2563]
 [ 49586  58327  54071  48710  42759  33864  26284  54137  45541   3134]
 [ 23247  32491  33477  32319  30202  26725  22065  46656  46906   3695]
 [ 11404  19528  21961  22166  21642  20396  17976  39911  47227   3990]
 [  5897  11609  14160  15338  15792  15539  14997  34809  46125   4409]
 [  3218   7093   9401  10819  11857  12319  12498  30310  44153   4729]
 [  1921   4574   6542   7784   8715   9584  10200  25956  41668   4888]
 [  3307   9653  14911  19109  23466  27777  31614  89951 183629  30238]
 [  1121   3645   6229   9166  12586  15764  19733  68616 194925  61872]]
2024-04-25 03:12:17,789 - INFO - Epoch: 7 | Train Loss: 5813.8669
2024-04-25 03:15:53,868 - INFO - Custom bins confusion matrix:
2024-04-25 03:15:53,869 - INFO - [[35745 51817 41209 27213 16584 10114  7390  9377  9673   218]
 [12759 27160 25720 19253 13417  9633  7113  9334 12927   324]
 [ 4080 12593 15118 12653  9869  7648  6101  8057 14761   472]
 [ 1246  5759  9010  8493  6896  5866  5200  7254 14618   645]
 [  351  2666  5130  5294  4883  4678  4048  6385 14264   653]
 [  142  1153  2440  3394  3320  3265  3258  5487 13744   586]
 [   33   511  1351  2018  2212  2360  2464  4304 13217   662]
 [   19   263   862  1391  1497  1484  1997  3697 12247   701]
 [   11   562  1368  2409  3291  4145  4647 13297 52687  4213]
 [    4   142   591   966  1353  1993  2539  6155 49427  8871]]
2024-04-25 03:15:55,672 - INFO - Epoch: 7 | Validation Loss: 2957.4002
2024-04-25 03:31:55,672 - INFO - Custom bins confusion matrix:
2024-04-25 03:31:55,674 - INFO - [[308677 184580 132814  99528  70287  43743  26056  22951  77909   2013]
 [142445 108553  86470  70050  55489  39625  27003  24031  75368   2549]
 [ 65968  62067  52817  46121  39160  30695  22807  21551  72082   3145]
 [ 31744  35877  33766  31506  28480  24479  19767  19119  69476   3569]
 [ 15806  21781  22306  21651  21164  19157  16474  17044  66707   4111]
 [  7990  13435  14702  15101  15436  14561  13610  15116  64024   4700]
 [  4394   7994   9751  10614  11317  11590  11383  13321  60838   5195]
 [  2426   5201   6528   7703   8336   8979   9053  11136  57070   5400]
 [  3818   9877  14589  18089  21681  25337  28014  36922 241190  34138]
 [  1328   3372   5805   8206  10810  13431  16651  24509 237323  72222]]
2024-04-25 03:32:00,474 - INFO - Epoch: 8 | Train Loss: 5520.0725
2024-04-25 03:35:36,571 - INFO - Custom bins confusion matrix:
2024-04-25 03:35:36,572 - INFO - [[46281 53709 38611 23868 13661  8532  5962  5318 13092   306]
 [18891 29741 25295 17959 11355  7468  5590  5113 15835   393]
 [ 6744 15552 15407 12113  8595  6568  4838  4448 16648   439]
 [ 2371  7403  9907  8600  6511  4991  4066  3962 16593   583]
 [  745  3863  5757  5697  4973  4008  3194  3210 16312   593]
 [  253  1804  3309  3789  3422  2844  2626  2593 15485   664]
 [   76   740  1896  2296  2317  2200  2088  2269 14551   699]
 [   32   425  1052  1522  1713  1548  1470  1808 13750   838]
 [   39   722  1626  2693  3351  3794  4029  5135 60246  4995]
 [    4   168   515   848  1245  1489  2481  2993 51506 10792]]
2024-04-25 03:35:38,350 - INFO - Epoch: 8 | Validation Loss: 2877.4806
2024-04-25 03:51:32,642 - INFO - Custom bins confusion matrix:
2024-04-25 03:51:32,643 - INFO - [[333868 182692 127842  93918  66326  41712  24159  15097  80980   1964]
 [160159 109425  84712  67208  51987  37108  24674  16918  76897   2495]
 [ 76504  64093  53006  45192  37203  28821  21398  15811  71491   2894]
 [ 36694  38868  34791  31429  28044  23139  18118  14512  68779   3409]
 [ 18520  23679  23457  22141  20433  18690  15472  13174  66400   4235]
 [  9313  14346  15562  15335  15355  14347  12762  11659  65157   4839]
 [  5056   8636  10236  10874  11400  11306  10700  10235  62379   5575]
 [  2725   5325   6879   7633   8313   8652   8646   8572  59162   5925]
 [  4180   9949  14430  17819  20511  23592  25542  27625 251393  38614]
 [  1328   3437   5580   7618   9908  12204  14745  17840 238284  82713]]
2024-04-25 03:51:37,398 - INFO - Epoch: 9 | Train Loss: 5345.7447
2024-04-25 07:58:04,366 - INFO - Custom bins confusion matrix:
2024-04-25 07:58:04,366 - INFO - [[49909 52742 37249 23600 13487  8587  5560  4585 13317   304]
 [20823 29751 24714 17274 11136  7691  5686  4493 15635   437]
 [ 7393 15576 15506 12134  8493  6533  4934  4030 16109   644]
 [ 2471  7627 10172  8410  6526  5289  4149  3554 15862   927]
 [  765  3809  5723  5885  5208  4145  3153  2856 15857   951]
 [  329  1728  3166  3796  3574  3032  2601  2426 15082  1055]
 [  116   801  1657  2275  2570  2073  2096  2039 14318  1187]
 [   51   378  1033  1481  1856  1490  1341  1546 13650  1332]
 [   61   566  1576  2526  3476  3701  3817  4615 58579  7713]
 [   44   204   590   766  1220  1582  2140  2712 47448 15335]]
2024-04-25 07:58:05,868 - INFO - Epoch: 9 | Validation Loss: 2924.3686
2024-04-25 08:14:02,516 - INFO - Custom bins confusion matrix:
2024-04-25 08:14:02,518 - INFO - [[341242 180213 125232  92111  65471  41705  24558  15233  80858   1935]
 [164777 108583  83001  66176  51976  37037  24793  16912  75896   2432]
 [ 79201  64149  52237  44548  37057  28874  21101  15960  70503   2783]
 [ 38793  38891  34508  31319  27528  23001  18241  14523  67736   3243]
 [ 19488  24486  23308  22030  20599  18512  15487  12941  65630   3720]
 [  9926  14689  15515  15545  15274  14406  12746  11517  64705   4352]
 [  5236   8833  10334  11044  11480  11360  10659   9922  62253   5276]
 [  2910   5400   6869   7815   8111   8567   8557   8360  59306   5937]
 [  4475   9952  14124  17392  20075  23309  25079  26992 252742  39515]
 [  1472   3380   5286   7559   9795  11792  14362  17463 237107  85441]]
2024-04-25 08:14:07,341 - INFO - Epoch: 10 | Train Loss: 5257.5265
2024-04-25 08:17:41,781 - INFO - Custom bins confusion matrix:
2024-04-25 08:17:41,781 - INFO - [[53247 50936 34481 21838 13576  9032  6095  4558 15087   490]
 [21267 28730 23159 16479 10860  8159  5993  4854 17483   656]
 [ 7428 14608 14210 11473  8514  6294  5323  4627 18030   845]
 [ 2771  7397  8540  7737  6339  5113  4052  3911 18018  1109]
 [ 1038  3564  5044  5129  4606  3884  3550  3177 17243  1117]
 [  429  1727  2618  3535  2916  2854  2744  2561 16268  1137]
 [  147   856  1482  2027  2159  2035  2076  1987 15083  1280]
 [   38   522   879  1407  1432  1393  1537  1619 13986  1345]
 [   89   744  1462  2229  2792  3405  4176  5116 59010  7607]
 [   18   176   470   897  1295  1746  2368  2839 48683 13549]]
2024-04-25 08:17:43,617 - INFO - Epoch: 10 | Validation Loss: 3069.4844
2024-04-25 08:33:39,695 - INFO - Custom bins confusion matrix:
2024-04-25 08:33:39,695 - INFO - [[359189 177801 121818  89062  62602  39468  23741  14291  78577   2009]
 [174571 108743  82263  65133  49829  35412  23917  16234  73024   2457]
 [ 85348  64318  52226  43487  36215  28183  20549  15206  68081   2800]
 [ 41970  39811  34935  30801  27122  22409  17805  14144  65531   3255]
 [ 21139  24790  23778  22122  20482  18249  15250  12750  63827   3814]
 [ 10620  15006  15797  15823  15341  14466  12748  11322  62943   4609]
 [  5527   9027  10460  11111  11527  11433  10750   9848  61343   5371]
 [  2975   5563   6926   7830   8257   8648   8687   8304  58777   5865]
 [  4381   9993  14178  16973  19859  22541  24830  26677 255384  38839]
 [  1580   3323   5041   6943   8850  10985  13409  16303 237455  89768]]
2024-04-25 08:33:44,381 - INFO - Epoch: 11 | Train Loss: 5132.0325
2024-04-25 08:37:30,824 - INFO - Custom bins confusion matrix:
2024-04-25 08:37:30,825 - INFO - [[65001 52327 32357 19605 11588  7455  4951  3925 11647   484]
 [29178 30671 22714 15303  9902  7037  4963  3834 13487   551]
 [11937 17603 14366 11016  7623  5932  4719  3629 13891   636]
 [ 4497  9678  9939  8183  5912  4757  3696  3293 14137   895]
 [ 1472  5037  6399  6012  4632  3923  3093  2670 14078  1036]
 [  497  2472  3618  4007  3499  2949  2559  2345 13744  1099]
 [  153  1123  1932  2575  2480  2195  1969  1958 13690  1057]
 [   37   539  1244  1550  1754  1596  1474  1616 13053  1295]
 [   43   797  1517  2401  3237  3572  3841  4474 58251  8497]
 [   26   171   398   808  1323  1586  1977  2591 46631 16530]]
2024-04-25 08:37:32,395 - INFO - Epoch: 11 | Validation Loss: 2841.8767
2024-04-25 08:52:45,481 - INFO - Custom bins confusion matrix:
2024-04-25 08:52:45,483 - INFO - [[388597 174001 117461  83315  57451  36492  21891  13103  74409   1838]
 [193708 108495  79666  61548  46671  33051  22317  15020  68897   2210]
 [ 96782  65283  51581  42634  34563  26187  19232  14011  63611   2529]
 [ 48944  41356  34995  30235  26326  21630  16865  13010  61573   2849]
 [ 24563  26435  24302  22058  20267  18025  14469  11823  60930   3329]
 [ 12450  15966  16112  15551  15170  14177  12492  10996  61721   4040]
 [  6091   9433  10728  11215  11426  11204  10700   9919  60542   5139]
 [  3153   5584   7049   7674   8214   8351   8704   8205  59059   5839]
 [  4454   9174  13081  15873  18431  21236  23342  25142 260697  42225]
 [  1347   2840   4332   5990   7758   9748  12037  14916 233984 100705]]
2024-04-25 08:52:49,611 - INFO - Epoch: 12 | Train Loss: 4902.7037
2024-04-25 08:55:58,961 - INFO - Custom bins confusion matrix:
2024-04-25 08:55:58,961 - INFO - [[74083 52506 29922 17342 10329  6158  4362  3180 10739   719]
 [33979 32265 21949 13623  8513  6250  4446  3268 12491   856]
 [13891 18939 14795  9965  7104  5284  3845  2976 13486  1067]
 [ 5269 10953 10374  7746  5544  4117  3167  2760 13604  1453]
 [ 1948  5693  6610  5663  4711  3537  2573  2346 13512  1759]
 [  745  2761  4030  3747  3268  2707  2295  2045 13186  2005]
 [  235  1303  2233  2702  2318  1976  1662  1596 13014  2093]
 [   52   652  1399  1753  1692  1347  1267  1266 12345  2385]
 [  116  1035  1856  2441  3204  3342  3506  3833 52493 14804]
 [   32   206   491   931  1304  1575  1828  2284 40283 23107]]
2024-04-25 08:56:00,457 - INFO - Epoch: 12 | Validation Loss: 2867.1471
2024-04-25 09:09:18,361 - INFO - Custom bins confusion matrix:
2024-04-25 09:09:18,362 - INFO - [[401072 173323 115135  81994  55713  34582  20524  12257  72084   1874]
 [201836 109685  78873  60569  45333  31854  21111  14040  66043   2239]
 [100403  67728  52527  42638  33896  25123  18238  12836  60618   2406]
 [ 51043  42897  35445  30794  26087  21046  16075  12543  59113   2740]
 [ 25589  27064  24282  22645  20464  17707  14382  11571  59154   3343]
 [ 12357  16357  17002  16087  15433  14169  12437  10727  59813   4293]
 [  6219   9516  10995  11355  11592  11654  10469   9405  59991   5201]
 [  3147   5549   6889   7744   8441   8710   8472   8151  58719   6010]
 [  4258   9007  12609  15867  18462  20647  22925  24493 261462  43925]
 [  1256   2622   4214   5588   7507   9048  11108  13367 227588 111359]]
2024-04-25 09:09:22,656 - INFO - Epoch: 13 | Train Loss: 4738.3555
2024-04-25 09:13:56,204 - INFO - Custom bins confusion matrix:
2024-04-25 09:13:56,205 - INFO - [[85811 51924 27651 15185  8891  5379  3503  2414  8155   427]
 [40249 33789 20889 12766  7896  5315  3615  2591  9944   586]
 [17446 20686 14642  9606  6729  4849  3190  2362 10980   862]
 [ 6890 12810 10637  7540  5177  3844  3045  2400 11430  1214]
 [ 2510  6915  7556  5846  4340  3314  2385  2079 11981  1426]
 [  867  3307  4864  4245  3300  2746  2140  1719 12089  1512]
 [  282  1505  2551  3195  2397  2023  1761  1542 12209  1667]
 [   63   744  1450  1978  1867  1547  1250  1331 12052  1876]
 [  153   977  1988  2692  3544  3911  4013  4189 53894 11269]
 [   32   281   687   998  1457  1710  2178  2613 42620 19465]]
2024-04-25 09:13:57,971 - INFO - Epoch: 13 | Validation Loss: 2796.9916
2024-04-25 09:32:22,713 - INFO - Custom bins confusion matrix:
2024-04-25 09:32:22,714 - INFO - [[419003 170413 112162  78367  52729  32983  19070  11635  70343   1853]
 [213549 109123  77867  58937  43699  30230  19965  12921  63165   2127]
 [108139  67851  51502  41675  32525  24675  17455  12315  58134   2142]
 [ 55009  43773  35864  30476  25601  20281  15561  11900  56897   2421]
 [ 27477  27740  24825  22537  20217  17347  14123  11254  57784   2897]
 [ 13195  16832  16835  16220  15347  14327  12165  10427  59364   3963]
 [  6485   9791  10953  11329  11581  11177  10549   9565  59998   4969]
 [  3241   5676   6859   7569   8132   8400   8490   8030  59793   5642]
 [  4430   8841  12399  15291  17606  19748  22038  23546 264620  45136]
 [  1254   2558   3676   5175   6687   8189  10130  12482 225877 117629]]
2024-04-25 09:32:27,219 - INFO - Epoch: 14 | Train Loss: 4644.3945
2024-04-25 09:36:37,201 - INFO - Custom bins confusion matrix:
2024-04-25 09:36:37,201 - INFO - [[82743 50052 28102 16028  9662  6033  4119  2846  9199   556]
 [38405 32227 21656 12848  7888  5361  4034  3229 11288   704]
 [16221 19550 14594 10140  6692  4840  3606  2737 12000   972]
 [ 5968 11766 10614  7602  5418  4152  3144  2609 12396  1318]
 [ 2226  5608  7236  5895  4644  3377  2725  2224 12885  1532]
 [  782  2724  3832  4086  3583  2742  2161  2097 12965  1817]
 [  215  1181  2037  2555  2569  2088  1747  1700 13092  1948]
 [   86   477  1083  1562  1719  1495  1396  1366 12904  2070]
 [  306   794  1565  2293  2833  3232  3357  3530 55465 13255]
 [   63   275   524   744  1165  1535  1727  2139 41355 22514]]
2024-04-25 09:36:39,600 - INFO - Epoch: 14 | Validation Loss: 2726.8163
2024-04-25 09:36:39,618 - INFO - Experiment ended. Checkpoints stored =)
